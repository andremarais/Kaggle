store190 <- store190[1:(nrow(store190) - nrow(store190) %% no.of.trading.days),][store190$Sales != 0,]
ts190 <- ts(store190$Sales, frequency = no.of.trading.days)
plot(decompose(ts190))
plot(decompose(ts190)$x - decompose(ts190)$random)
lines(decompose(ts190)$x, col = 'red')
store190$PromoMonth <- sapply(store190$Date, function(x) if (grepl(format(x, '%b'), stores$PromoInterval[stores$Store == 190])) 1 else 0)
function (X, FUN, ...)
?grepl
library(data.table)
install.packages("data.table")
install.packages("h20")
install.packages("h2o")
library(data.table)
library(h2o)
cat("reading the train and test data (with data.table) \n")
train <- fread("../train.csv",stringsAsFactors = T)
setwd("~/Documents/USCA/Rossmann/Kaggle")
train <- fread("../train.csv",stringsAsFactors = T)
train <- fread("./train.csv",stringsAsFactors = T)
setwd("~/Documents/USCA/Rossmann/Kaggle/Big Hand")
test  <- fread("../test.csv",stringsAsFactors = T)
train <- fread("../train.csv",stringsAsFactors = T)
store <- fread("../store.csv",stringsAsFactors = T)
train <- merge(train,store,by="Store")
test <- merge(test,store,by="Store")
cat("train data column names and details\n")
summary(train)
cat("test data column names and details\n")
summary(test)
## more care should be taken to ensure the dates of test can be projected from train
## decision trees do not project well, so you will want to have some strategy here, if using the dates
train[,Date:=as.Date(Date)]
test[,Date:=as.Date(Date)]
train[,month:=as.integer(format(Date, "%m"))]
train[,year:=as.integer(format(Date, "%y"))]
train[,Store:=as.factor(as.numeric(Store))]
test[,month:=as.integer(format(Date, "%m"))]
test[,year:=as.integer(format(Date, "%y"))]
test[,Store:=as.factor(as.numeric(Store))]
train[,logSales:=log1p(Sales)]
View(train)
h2o.init(nthreads=-1,max_mem_size='6G')
trainHex<-as.h2o(train)
features<-colnames(train)[!(colnames(train) %in% c("Id","Date","Sales","logSales","Customers"))]
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 100,
max_depth = 30,
nbins_cats = 1115, ## allow it to fit store ID
training_frame=trainHex)
h2o.init(nthreads=-1,max_mem_size='6G')
trainHex<-as.h2o(train)
## Set up variable to use all features other than those specified here
features<-colnames(train)[!(colnames(train) %in% c("Id","Date","Sales","logSales","Customers"))]
## Train a random forest using all default parameters
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 100,
nbins_cats = 1115, ## allow it to fit store ID
max_depth = 30,
training_frame=trainHex)
summary(rfHex)
testHex<-as.h2o(test)
predictions<-as.data.frame(h2o.predict(rfHex,testHex))
pred <- expm1(predictions[,1])
summary(pred)
submission <- data.frame(Id=test$Id, Sales=pred)
cat("saving the submission file\n")
write.csv(submission, "h2o_rf.csv",row.names=F)
View(test)
View(train[sample(train,nrow(train),100)])
View(train[sample(train,nrow(train),100)],)
View(train[sample(train,nrow(train),100)],)
View(train[sample(nrow(train),100)])
View(test)
View(test[which(train$Store==1),])
?h2o
??h20
?h2o
?h2ots190
ts190
?ts
?ts
?ts
no.of.trading.days <- length(unique(store190$DayOfWeek[store190$Open == 1]))
store190 <- store190[1:(nrow(store190) - nrow(store190) %% no.of.trading.days),][store190$Sales != 0,]
View(store190)
AirPassengers
str(AirPassengers)
str(AirPassengers)
?arima
fit(arima(ts190))
os <- read.delim("opensignals_file_2015-10-09_13-03-34.txt")
setwd("~/Documents/MindLab")
os <- read.delim("opensignals_file_2015-10-09_13-03-34.txt")
os <- fread("opensignals_file_2015-10-09_13-03-34.txt")
?fre
?read.
os <- read.csv("opensignals_file_2015-10-09_13-03-34.txt")
?read.csv
os <- read.table("opensignals_file_2015-10-09_13-03-34.txt".header=FALSE,skip=3)
os <- read.table("opensignals_file_2015-10-09_13-03-34.txt",header=FALSE,skip=3)
View(os)
colnames(os)
colnames(os) <- c("nSeq", "I1", "I2", "I3", "I4", "A1", "A2")
View(os)
summary(os)
View(os[which(os$I2==0),])
View(os[which(os$I2==1),])
View(os[which(os$I2==0),])
library(ggplot2)
ggplot(os,aes(y=I2))+geom_line()
qplot(os$I2)
plot(os$I2)
ggplot(os,aes(y=I2))+geom_point()
ggplot(os)+geom_point()
store190 <- store190[1:(nrow(store190) - nrow(store190) %% no.of.trading.days),][store190$Sales != 0,]
plot(decompose(ts190))
plot(decompose(ts190)$x - decompose(ts190)$random)
plot(decompose(ts190))
ggplot(cbind(store190, pred190)) + geom_line(aes(x = Date, y = Sales), col = 'dodgerblue3') + geom_line(aes(x = Date, y = pred190), col = 'tomato3')
rf190 <- randomForest(data = store190, Sales ~ DayOfWeek + Customers + Open + Promo + StateHoliday + SchoolHoliday + PromoMonth)
library(randomForest)
install.packages('randomForest')
ggplot(train.ss[train.ss$Store == 190,])+ geom_line(aes(x = Date, y = Sales))
ggplot(os)+geom_point()
View(os)
View(os)
View(os)
View(os)
ggplot(os)+geom_point(aes(x=nSeq,y=I2))
View(os)
ggplot(os)+geom_point(aes(x=row.names(os),y=I2))
plot(os$I2)
setwd("~/Documents/MindLab/Data/EyeDataTest")
pupil <- read.csv("eyedata.csv")
pupil <- read.csv("eyedata.csv",delim=';')
pupil <- read.csv("eyedata.csv",sep=';')
View(pupil)
View(pupil)
pp <- read.csv("eyedata.csv",sep=';')
row.names(pp)
col.names(pp)
colnames(pp)
plot(pp$PupilLeft)
plot(os$I2,type='l')
os <- read.table("opensignals_file_2015-10-09_13-03-34.txt",header=FALSE,skip=3)
colnames(os) <- c("nSeq", "I1", "I2", "I3", "I4", "A1", "A2")
setwd("~/Documents/MindLab/Data/Test_20151009")
os <- read.table("opensignals_file_2015-10-09_13-03-34.txt",header=FALSE,skip=3)
plot(os$I2,type='l')
plot(os$I2)
os <- read.table("opensignals_file_2015-10-09_13-03-34.txt",header=FALSE,skip=3)
colnames(os) <- c("nSeq", "I1", "I2", "I3", "I4", "A1", "A2")
plot(os$I2)
plot(os$I2)
gc()
library(RJDBC)
library(xlsx)
library(dplyr)
if (.Platform$OS.type == "unix"){
drv <- JDBC("net.sourceforge.jtds.jdbc.Driver",
"/opt/rjdbc/jtds/jtds-1.3.1.jar")
} else {
drv <- JDBC("com.microsoft.sqlserver.jdbc.SQLServerDriver",
"C:/Program Files/Microsoft SQL Server JDBC Driver 3.0/sqljdbc_3.0
/enu/sqljdbc4.jar")
}
percent <- function(x, digits = 2, format = "f", ...) {
paste0(formatC(100 * x, format = format, digits = digits, ...), "%")
}
simpleCap <- function(x) {
s<- tolower(x)
s <- strsplit(s, " ")[[1]]
paste(toupper(substring(s, 1,1)), substring(s, 2),
sep="", collapse=" ")
}
conn <- dbConnect(drv,"jdbc:jtds:sqlserver://cedwsqlprod1.momentum.co.za;user=lopienaar;password=P!esang53;domain=metmom;APPNAME=ClientDashboard;PROGNAME=R")
sqlText <- "select distinct rbppm.PeriodicDateKey,p.PolicyFull,rbt.RetailBenefitTypeDesc
from MOMDW1.fact.RetailBenefitPolicyPeriodicMovement rbppm
inner join MOMDW1.dim.RetailBenefitType rbt
on rbt.RetailBenefitTypeKey = rbppm.RetailBenefitTypeKey
inner join MOMDW1.dim.Policy p on p.PolicyKey = rbppm.PolicyKey
where p.ProductHouseDesc = 'Myriad'
and p.InforceIndicator = 'INF'
and rbt.RetailBenefitTypeDesc <> 'Unknown'
and rbppm.PeriodicDateKey in ('20130103','20140103','20150103')"
Ben <-  dbGetQuery(conn, sqlText)
conn <- dbConnect(drv,"jdbc:jtds:sqlserver://cedwsqlprod1.momentum.co.za;user=lopienaar;password=P!esang53;domain=metmom;APPNAME=ClientDashboard;PROGNAME=R")
sqlText <- "select distinct rbppm.PeriodicDateKey,p.PolicyFull,rbt.RetailBenefitTypeDesc
from MOMDW1.fact.RetailBenefitPolicyPeriodicMovement rbppm
inner join MOMDW1.dim.RetailBenefitType rbt
on rbt.RetailBenefitTypeKey = rbppm.RetailBenefitTypeKey
inner join MOMDW1.dim.Policy p on p.PolicyKey = rbppm.PolicyKey
where p.ProductHouseDesc = 'Myriad'
and p.InforceIndicator = 'INF'
and rbt.RetailBenefitTypeDesc <> 'Unknown'
and rbppm.PeriodicDateKey in ('20130103','20140103','20150103')"
Ben <-  dbGetQuery(conn, sqlText)
library(gdata)
install.packages('gdata')
library(gdata)
aggregate.table
head(Ben)
aggregate.table(Ben,PolicyFull,RetailBenefitTypeDesc,nobs)
??aggregate.table
Sum.table <- table(PolicyFull,RetailBenefitTypeDesc)
?attach
attach(Ben)
Sum.table <- table(PolicyFull,RetailBenefitTypeDesc)
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20130103'],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20130103'])
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20130103')],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20130103')])
head(Sum.table)
View(Sum.table[1:1000,])
?colSums
colSums(Sum.table)
t<- colSums(Sum.table)
nrows(Sum.table)
nrow(Sum.table)
t<- colSums(Sum.table)/nrow(Sum.table)
t
percent(t)
t<- as.data.frame(colSums(Sum.table)/nrow(Sum.table))
percent(t)
View(t)
t$benefit <- rownames(t)
View(t)
colnames(t)
colnames(t) <- c('BenefCount','Benefit')
View(t)
colnames(t) <- c('BenefCountPerc','Benefit')
t$Perc <- percent(t$BenefCountPerc)
View(t)
?write.csv
write.csv(t,"BenfSplit_2013.csv")
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20140103')],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20130103')])
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20140103')],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20140103')])
t<- as.data.frame(colSums(Sum.table)/nrow(Sum.table))
t$benefit <- rownames(t)
colnames(t) <- c('BenefCountPerc','Benefit')
t$Perc <- percent(t$BenefCountPerc)
write.csv(t,"BenfSplit_2014.csv")
setwd("~/Documents")
write.csv(t,"BenfSplit_2014.csv")
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20130103')],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20130103')])
t<- as.data.frame(colSums(Sum.table)/nrow(Sum.table))
t$benefit <- rownames(t)
colnames(t) <- c('BenefCountPerc','Benefit')
t$Perc <- percent(t$BenefCountPerc)
write.csv(t,"BenfSplit_2014.csv")
write.csv(t,"BenfSplit_2013.csv")
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20140103')],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20140103')])
t<- as.data.frame(colSums(Sum.table)/nrow(Sum.table))
t$benefit <- rownames(t)
colnames(t) <- c('BenefCountPerc','Benefit')
t$Perc <- percent(t$BenefCountPerc)
write.csv(t,"BenfSplit_2014.csv")
Sum.table <- table(Ben$PolicyFull[which(Ben$PeriodicDateKey=='20150103')],Ben$RetailBenefitTypeDesc[which(Ben$PeriodicDateKey=='20150103')])
t<- as.data.frame(colSums(Sum.table)/nrow(Sum.table))
t$benefit <- rownames(t)
colnames(t) <- c('BenefCountPerc','Benefit')
t$Perc <- percent(t$BenefCountPerc)
write.csv(t,"BenfSplit_2015.csv")
sqlText <- "select distinct rbppm.PeriodicDateKey,p.PolicyFull,rbt.RetailBenefitTypeDesc,rbppm.API
from MOMDW1.fact.RetailBenefitPolicyPeriodicMovement rbppm
inner join MOMDW1.dim.RetailBenefitType rbt
on rbt.RetailBenefitTypeKey = rbppm.RetailBenefitTypeKey
inner join MOMDW1.dim.Policy p on p.PolicyKey = rbppm.PolicyKey
where p.ProductHouseDesc = 'Myriad'
and p.InforceIndicator = 'INF'
and rbt.RetailBenefitTypeDesc <> 'Unknown'
and rbppm.PeriodicDateKey in ('20130103','20140103','20150103')"
Ben <-  dbGetQuery(conn, sqlText)
conn <- dbConnect(drv,"jdbc:jtds:sqlserver://cedwsqlprod1.momentum.co.za;user=lopienaar;password=P!esang53;domain=metmom;APPNAME=ClientDashboard;PROGNAME=R")
sqlText <- "select distinct rbppm.PeriodicDateKey,p.PolicyFull,rbt.RetailBenefitTypeDesc,rbppm.API
from MOMDW1.fact.RetailBenefitPolicyPeriodicMovement rbppm
inner join MOMDW1.dim.RetailBenefitType rbt
on rbt.RetailBenefitTypeKey = rbppm.RetailBenefitTypeKey
inner join MOMDW1.dim.Policy p on p.PolicyKey = rbppm.PolicyKey
where p.ProductHouseDesc = 'Myriad'
and p.InforceIndicator = 'INF'
and rbt.RetailBenefitTypeDesc <> 'Unknown'
and rbppm.PeriodicDateKey in ('20130103','20140103','20150103')"
Ben <-  dbGetQuery(conn, sqlText)
?table
?aggregate
colnames(Ben)
aggregate(API ~ PeriodicDateKey + RetailBenefitTypeDesc,data = Ben, FUN = 'mean')
Ben.pol <- aggregate(API ~ PeriodicDateKey + RetailBenefitTypeDesc + PolicyFull,data = Ben, FUN = 'sum')
API.results <- aggregate(API ~ PeriodicDateKey + RetailBenefitTypeDesc,data = Ben.pol, FUN = 'mean')
View(API.results)
write.csv(API.results,file="Benf_API.csv")
setwd("~/Documents/USCA/Rossmann/Kaggle/Big Hand")
source(../common/loadclean.R)
source("../common/loadclean.R")
library(data.table)
library(h2o)
library(forecast)
source("../common/loadclean.R")
source("../common/loadclean.R")
str(train)
predictors <- names(train)[c(1, 2, 6, 7, 9:21)]
predictors
Store.Forecast <- read.csv("./Outputs/Store.Forecast.csv")
Store.Test.Forecast <- read.csv("./Outputs/Store.Test.Forecast.csv")
Store.Forecast <- read.csv("Store.Forecast.csv")
Store.Test.Forecast <- read.csv("Store.Test.Forecast.csv")
Store.Forecast <- read.csv("Store.Forecast.csv")
Store.Test.Forecast <- read.csv("Store.Test.Forecast.csv")
train[,Date:=as.Date(Date)]
str(train)
train$Date=as.Date(Date)
train$Date=as.Date(train$Date)
test$Date=as.Date(test$Date)
train[,month:=as.integer(format(Date, "%m"))]
library(data.table)
library(h2o)
library(forecast)
train[,month:=as.integer(format(Date, "%m"))]
as.data.table((train))
train <- as.data.table(train)
train[,month:=as.integer(format(Date, "%m"))]
train[,year:=as.integer(format(Date, "%y"))]
train[,Store:=as.factor(as.numeric(Store))]
test <- as.data.table(test)
test[,month:=as.integer(format(Date, "%m"))]
test[,year:=as.integer(format(Date, "%y"))]
test[,Store:=as.factor(as.numeric(Store))]
train[,logSales:=log1p(Sales)]
str(train)
str(Store.Forecast)
Store.Forecast <- Store.Forecast[,c('Store','Date','ArimaForecast')]
Store.Test.Forecast <- Store.Test.Forecast[,c('Store','Date','ArimaForecast')]
train <- merge(train,Store.Forecast,by=c('Store','Date'),all.x=TRUE)
str(train)
Store.Forecast <- read.csv("Store.Forecast.csv",stringsAsFactors = FALSE)
Store.Test.Forecast <- read.csv("Store.Test.Forecast.csv",stringsAsFactors = FALSE)
Store.Forecast <- Store.Forecast[,c('Store','Date','ArimaForecast')]
Store.Test.Forecast <- Store.Test.Forecast[,c('Store','Date','ArimaForecast')]
train <- merge(train,Store.Forecast,by=c('Store','Date'),all.x=TRUE)
str(train)
str(Store.Forecast)
Store.Forecast$Date=as.Date(Store.Forecast$Date)
Store.Test.Forecast$Date=as.Date(Store.Test.Forecast$Date)
Store.Forecast <- Store.Forecast[,c('Store','Date','ArimaForecast')]
Store.Test.Forecast <- Store.Test.Forecast[,c('Store','Date','ArimaForecast')]
train <- merge(train,Store.Forecast,by=c('Store','Date'),all.x=TRUE)
train$ArimaForecast[which(is.na(train$ArimaForecast))] <- -99
colnames(train)
predictors <- names(train)[c(1, 2, 6, 7, 9:21,23)]
str(train)
for (p in predictors) {
if (class(train[[p]]) == "character") {
levels <- unique(c(train[[p]], test[[p]]))
train[[p]] <- as.integer(factor(train[[p]], levels=levels))
test[[p]]  <- as.integer(factor(test[[p]],  levels=levels))
}
}
str(train)
h2o.init(nthreads=-1,max_mem_size='6G')
trainHex<-as.h2o(train)
features<-colnames(train)[!(colnames(train) %in% c("Id","Date","Sales","logSales","Customers"))]
?h2o.randomForest
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 200,
max_depth = 50,
nbins = 1115,
binomial_double_trees = TRUE,
nbins_cats = 1115, ## allow it to fit store ID
training_frame=trainHex)
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 200,
max_depth = 50,
nbins = 1115,
nbins_top_level=1115,
binomial_double_trees = TRUE,
nbins_cats = 1115, ## allow it to fit store ID
training_frame=trainHex)
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 200,
max_depth = 50,
nbins = 1115,
nbins_top_level=5000,
binomial_double_trees = TRUE,
nbins_cats = 1115, ## allow it to fit store ID
training_frame=trainHex)
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 200,
max_depth = 50,
nbins = 500,
#nbins_top_level=5000,
binomial_double_trees = TRUE,
nbins_cats = 1115, ## allow it to fit store ID
training_frame=trainHex)
h2o.init(nthreads=-1,max_mem_size='6G')
trainHex<-as.h2o(train)
## Set up variable to use all features other than those specified here
features<-colnames(train)[!(colnames(train) %in% c("Id","Date","Sales","logSales","Customers"))]
## Train a random forest using all default parameters
rfHex <- h2o.randomForest(x=features,
y="logSales",
ntrees = 200,
max_depth = 40,
#nbins_top_level=5000,
binomial_double_trees = TRUE,
nbins_cats = 1115, ## allow it to fit store ID
training_frame=trainHex)
trainHex<-as.h2o(train)
h2o.init(ip='10.1.26.204',port=54321)
h2o.getConnection()
h2o.getConnection(ip='10.1.26.204')
?"h2o-package"
h2o.init(ip='10.1.26.204',port=54321,startH2O = FALSE)
h2o.init(ip='10.1.26.204',port=54321,startH2O = FALSE)
trainHex<-as.h2o(train)
# H2O Random Forest Starter Script
# Based on Ben Hamner script from Springleaf
# https://www.kaggle.com/benhamner/springleaf-marketing-response/random-forest-example
# Forked from Random Forest Example by Michael Pawlus
# Use data.table and H2O to create random forest predictions for the entire
#   training set.
# This is a starter script so it mostly uses the provided fields, as is.
# A log transform has been applied to the Sales, year and month are used,
#  and the Store ID is used as a factor.
# It does not remove the 0 readings, which may help, since we are not judged
#  on those entries. The model finds "Open" to be the most important feature,
#  which makes sense, since Sales are 0 when the store is not open. However,
#  since observations with 0 Sales are discarded by Kaggle upon judging, it
#  may be a better strategy to remove them, as Michael's original script does.
# To make the benchmark a little more competitive, this has more and deeper
#  trees than the original. If you want to see it run faster, you can lower those
#  settings while you work through some other parts of the model, and increase them
#  later.
# Also, the h2o.gbm() has many shared parameters, so you can try that out as well,
#  and these parameters will work (though you probably don't want depth 30 for GBM).
# And to add variety, you can try out h2o.glm(), a regularized GLM, or
#  h2o.deeplearning(), for deep neural networks. This code will work for either with
#  the exception of the ntrees, max_depth, and nbins_cats, which are decision tree
#  parameters.
# Good luck!
library(data.table)
library(h2o)
library(forecast)
source("../common/loadclean.R")
train <- as.data.table(train)
test <- as.data.table(test)
## more care should be taken to ensure the dates of test can be projected from train
## decision trees do not project well, so you will want to have some strategy here, if using the dates
train[,Date:=as.Date(Date)]
test[,Date:=as.Date(Date)]
# seperating out the elements of the date column for the train set
train[,month:=as.integer(format(Date, "%m"))]
train[,year:=as.integer(format(Date, "%y"))]
train[,Store:=as.factor(as.numeric(Store))]
test[,month:=as.integer(format(Date, "%m"))]
test[,year:=as.integer(format(Date, "%y"))]
test[,Store:=as.factor(as.numeric(Store))]
## log transformation to not be as sensitive to high sales
## decent rule of thumb:
##     if the data spans an order of magnitude, consider a log transform
train[,logSales:=log1p(Sales)]
#View(train[sample(nrow(train),1000),])
#View(train[which(train$Store==7),])
Store.Forecast <- train[1,]
Store.Forecast$ArimaForecast<-0
Store.Forecast<- Store.Forecast[which(is.na(Store.Forecast$text)), ]
z<-1
StoreCheck <- train[which(train$Store==z&train$DayOfWeek<7),]
StoreCheck <- StoreCheck[order(StoreCheck$Date),]
#StoreCheck$NewSales <- StoreCheck$Sales
StoreCheck$Sales[which(StoreCheck$Sales==0)] <- mean(StoreCheck$Sales)
StoreCheck$logSales<-log1p(StoreCheck$Sales)
sc_ts <- ts(StoreCheck$logSales[1:(nrow(StoreCheck)-42)],frequency=6)
fit <- nnetar(sc_ts)
plot(forecast.nnetar(fit,h=42,level=c(0,1)))
z<-172
print(z)
StoreCheck <- train[which(train$Store==z&train$DayOfWeek<7),]
StoreCheck <- StoreCheck[order(StoreCheck$Date),]
#StoreCheck$NewSales <- StoreCheck$Sales
StoreCheck$Sales[which(StoreCheck$Sales==0)] <- mean(StoreCheck$Sales)
StoreCheck$logSales<-log1p(StoreCheck$Sales)
sc_ts <- ts(StoreCheck$logSales[1:(nrow(StoreCheck)-42)],frequency=6)
fit <- nnetar(sc_ts)
plot(forecast.nnetar(fit,h=42,level=c(0,1)))
n<-nrow(StoreCheck)
?while
()
??while
()
sc_ts <- ts(StoreCheck$logSales[1:(n-42)],frequency=6)
fit <- nnetar(sc_ts)
#plot(forecast.nnetar(fit,h=42,level=c(0,1)))
f <- forecast.nnetar(fit,h=42,level=c(0,1))
New.Forecast <-StoreCheck[(n-41):n,]
New.Forecast$ArimaForecast <- as.numeric(f$mean)
Store.Forecast <-rbind(Store.Forecast,New.Forecast)
n <- n-42
sc_ts <- ts(StoreCheck$logSales[1:(n-42)],frequency=6)
fit <- nnetar(sc_ts)
#plot(forecast.nnetar(fit,h=42,level=c(0,1)))
f <- forecast.nnetar(fit,h=42,level=c(0,1))
New.Forecast <-StoreCheck[(n-41):n,]
New.Forecast$ArimaForecast <- as.numeric(f$mean)
Store.Forecast <-rbind(Store.Forecast,New.Forecast)
View(Store.Forecast)
View(store)
?nnetar
